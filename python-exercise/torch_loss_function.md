## loss functions

## nn.L1Loss


```python
# abs(x-y), MAE

import torch
import torch.nn as nn

loss = nn.L1Loss()
input = torch.randn(3, 5, requires_grad=True)
target = torch.randn(3, 5)
output = loss(input, target)
output.backward()

print(input)
print(target)
print(output.item())
```

    tensor([[ 0.7605, -1.0964,  0.4791,  2.0017, -0.1922],
            [-0.5036,  0.2913,  0.5596, -1.0122,  0.0164],
            [-0.5685,  0.5142, -1.1501, -0.2089,  1.5148]], requires_grad=True)
    tensor([[ 1.5721, -0.2614, -0.0530, -1.1989, -0.8596],
            [-0.1491,  0.1433,  1.3588,  1.4405, -0.0807],
            [-1.8886,  0.5506, -0.8551, -0.9722, -0.5763]])
    0.960276186466217


## nn.MSELoss


```python
# (x-y)^2

import torch
import torch.nn as nn

loss = nn.MSELoss()
input = torch.randn(3, 5, requires_grad=True)
target = torch.randn(3, 5)
output = loss(input, target)
output.backward()

print(input)
print(target)
print(output.item())
```

    tensor([[-0.0167,  1.1569, -0.4612,  1.0216,  0.6583],
            [ 0.0221,  1.4626,  0.2428, -2.8949, -0.9363],
            [ 0.3073, -0.3701, -0.8702, -1.0569,  0.1138]], requires_grad=True)
    tensor([[-0.7302, -0.0280,  1.8604, -0.5798, -1.1704],
            [-0.6054,  0.2883,  0.7726,  0.1433,  0.2233],
            [ 0.5878, -0.6995,  1.2481,  1.3885,  0.0883]])
    2.4330132007598877


## nn.CrossEntropyLoss


```python
# C개 아이템을 classify할 때 사용
# input은 (N, C), target은 (N), output은 scalar (N)
# 즉 input중 가장 높은 확률인 아이템이 몇번째인가?가 target이고 그에 따른 loss를 계산한다.

import torch
import torch.nn as nn

loss = nn.CrossEntropyLoss()
input = torch.randn(3, 5, requires_grad=True)
target = torch.empty(3, dtype=torch.long).random_(5)
output = loss(input, target)
output.backward()

print(input)
print(target)
print(output.item())
```

    tensor([[ 0.1953, -0.2326,  0.4299,  2.1273, -0.6154],
            [ 0.2145,  1.3576, -0.7440, -0.0087, -0.7759],
            [-0.7721,  0.0792,  0.3817, -0.8920,  1.1659]], requires_grad=True)
    tensor([3, 4, 4])
    1.2837985754013062


## nn.CTCLoss


```python
import torch
import torch.nn as nn

# Target are to be padded
T = 50      # Input sequence length
C = 20      # Number of classes (including blank)
N = 16      # Batch size
S = 30      # Target sequence length of longest target in batch (padding length)
S_min = 10  # Minimum target length, for demonstration purposes

# Initialize random batch of input vectors, for *size = (T,N,C)
input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()

# Initialize random batch of targets (0 = blank, 1:C = classes)
target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)

input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)
target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)
ctc_loss = nn.CTCLoss()
loss = ctc_loss(input, target, input_lengths, target_lengths)
loss.backward()
print(input)
print(target)
print(loss.item())

 # Target are to be un-padded
T = 50      # Input sequence length
C = 20      # Number of classes (including blank)
N = 16      # Batch size

# Initialize random batch of input vectors, for *size = (T,N,C)
input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()
input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)

# Initialize random batch of targets (0 = blank, 1:C = classes)
target_lengths = torch.randint(low=1, high=T, size=(N,), dtype=torch.long)
target = torch.randint(low=1, high=C, size=(sum(target_lengths),), dtype=torch.long)
ctc_loss = nn.CTCLoss()
loss = ctc_loss(input, target, input_lengths, target_lengths)
loss.backward()
print(input)
print(target)
print(loss.item())
```

    tensor([[[-2.5329, -2.4167, -4.6062,  ..., -2.6445, -3.6700, -1.7473],
             [-2.6917, -3.9455, -1.5118,  ..., -3.7979, -3.6144, -4.4850],
             [-5.6594, -3.6181, -2.7028,  ..., -3.8040, -5.0931, -2.7329],
             ...,
             [-3.7280, -1.1915, -1.6541,  ..., -3.1245, -5.3550, -4.3243],
             [-2.9134, -4.0752, -3.7076,  ..., -1.8678, -2.6256, -3.7364],
             [-4.4078, -3.7186, -2.9255,  ..., -2.2417, -3.6300, -4.4536]],
    
            [[-2.4908, -3.0555, -5.6445,  ..., -3.6066, -2.9827, -4.1207],
             [-3.0414, -5.0310, -4.5157,  ..., -4.1743, -3.9346, -2.3865],
             [-3.5917, -2.7929, -4.8048,  ..., -4.1712, -3.1314, -2.7879],
             ...,
             [-4.6594, -2.8234, -4.4003,  ..., -3.4566, -1.6748, -3.6528],
             [-3.4468, -3.5274, -3.8809,  ..., -4.5721, -3.6471, -2.4532],
             [-4.0472, -2.4555, -2.3619,  ..., -2.2169, -4.8382, -4.0271]],
    
            [[-2.2551, -2.6758, -3.2624,  ..., -2.1866, -3.7552, -3.7573],
             [-3.6472, -3.1211, -3.3764,  ..., -1.3231, -2.6341, -4.6711],
             [-2.8666, -3.0368, -4.8269,  ..., -3.7911, -3.8579, -5.7392],
             ...,
             [-2.8925, -4.1891, -3.7377,  ..., -2.4641, -2.7607, -2.9651],
             [-6.0934, -4.2369, -2.4160,  ..., -3.8530, -4.0573, -3.4404],
             [-2.1601, -2.6529, -3.0026,  ..., -2.1246, -3.4227, -4.8418]],
    
            ...,
    
            [[-1.8647, -3.1083, -1.9240,  ..., -4.0195, -4.6834, -3.6492],
             [-3.2730, -1.4793, -4.5319,  ..., -2.8403, -3.8578, -2.6679],
             [-3.7610, -4.2307, -3.1652,  ..., -3.2934, -2.7772, -3.5700],
             ...,
             [-2.9036, -2.2150, -3.1947,  ..., -2.8630, -3.8167, -4.0890],
             [-3.6345, -4.5397, -3.7854,  ..., -2.3256, -4.4530, -5.9941],
             [-4.8531, -3.3166, -3.5877,  ..., -4.7171, -2.0296, -2.8203]],
    
            [[-4.2339, -1.9059, -1.9210,  ..., -2.9432, -2.4248, -3.5775],
             [-2.0349, -2.1489, -3.7091,  ..., -2.0628, -3.8767, -4.8455],
             [-2.8768, -3.3464, -3.2856,  ..., -3.3419, -4.4123, -3.2221],
             ...,
             [-4.5732, -4.5319, -3.0395,  ..., -1.6275, -5.0536, -3.4816],
             [-4.7467, -3.5268, -2.2060,  ..., -4.2344, -1.4324, -4.4045],
             [-2.9519, -6.0235, -5.9505,  ..., -3.4615, -4.1295, -2.9309]],
    
            [[-3.9455, -4.1605, -4.8399,  ..., -2.2470, -3.9921, -3.1552],
             [-2.1364, -3.7570, -1.5155,  ..., -2.9617, -4.8371, -1.9665],
             [-4.1988, -4.6472, -2.6650,  ..., -4.2043, -3.6931, -3.0298],
             ...,
             [-3.0547, -2.7776, -3.0659,  ..., -2.2859, -4.4283, -2.9995],
             [-3.9386, -3.2350, -3.8532,  ..., -3.7142, -2.8808, -1.7942],
             [-3.4925, -2.3705, -3.7173,  ..., -2.5520, -5.0231, -2.2185]]],
           requires_grad=True)
    tensor([[16,  6, 18,  5,  5, 14,  3,  4, 12, 19,  6,  7,  3, 15, 12,  7, 14, 17,
              3, 19, 16,  8,  8, 16,  8, 12,  6,  3, 17,  6],
            [ 5, 12, 19, 11,  4,  3,  1,  8, 10, 19, 13,  6, 13,  9,  8, 13,  8, 15,
              1, 15, 12,  9, 13, 18,  4,  6,  8, 19, 11,  8],
            [ 8, 13,  6,  9, 16,  1,  7, 13, 14, 19,  6, 11,  8,  5,  4, 11,  2, 13,
             18, 18, 19,  6,  8,  1,  1,  3,  1, 11,  4, 18],
            [ 5, 12,  8,  3,  9,  2,  4, 16, 14,  4, 17,  4,  5,  7, 15, 17, 13,  7,
              4, 15, 11,  1,  3, 18, 17, 16,  8,  6,  1, 15],
            [12,  2,  7, 13,  3, 17, 13, 18, 12, 15,  8, 13, 19,  7, 18, 11,  8, 11,
              1,  5, 19, 17, 16,  3,  3,  3,  8, 15,  3,  8],
            [ 6, 14,  2,  5,  2,  2, 11,  2,  6, 17, 12, 18, 18,  6, 17, 19,  5, 17,
             10,  6,  3,  5,  8,  9,  5, 12, 18,  9,  4,  7],
            [15, 17, 11,  6, 11,  6,  9,  6, 14,  8, 17,  3, 16,  2, 17,  5, 13, 15,
             16, 11, 16, 16,  3, 19, 15, 11,  4,  4, 16, 19],
            [16, 14,  5, 12, 17,  1, 17,  3, 12, 15,  3,  3,  7, 15, 18, 17, 18, 14,
             13, 10, 18,  7,  6, 15,  5, 19, 11, 10, 15,  5],
            [17,  1,  2,  6,  2,  1, 13, 19, 17, 15, 15,  2, 12, 19, 16, 10,  7, 10,
              4, 13,  4, 17,  9, 17, 10, 16,  9,  1, 18, 19],
            [ 1, 16, 14, 12,  8,  8,  7,  7,  5, 12, 16,  1,  2,  9, 15, 18, 13, 12,
              4,  6,  7, 13, 18,  6,  9, 15,  6, 18,  8,  9],
            [ 7,  9,  8, 16, 13, 10, 18, 16, 18,  2,  5, 12, 14, 14, 11, 14,  8, 13,
             11, 18, 13, 12,  2,  5, 14, 17,  9, 19, 17, 14],
            [ 3, 17,  1, 14,  1, 12,  3, 10,  3, 13,  7, 14, 18, 15,  5, 11, 15, 10,
              4,  1, 13,  3,  6, 10, 15, 19, 18,  1,  6,  6],
            [12,  9, 15, 19, 18,  7, 19, 17, 17, 14, 19,  4, 18, 10, 10, 11,  2,  9,
             11, 11, 11,  7,  8, 17, 10, 15,  2,  3, 19,  5],
            [ 5,  3, 14,  2, 11, 14,  4,  2, 14,  4,  8, 14,  7, 16,  3, 14,  7,  4,
             17,  1, 18,  6, 10, 15, 14,  8, 11,  5,  6,  9],
            [ 8,  8, 16, 15, 18, 15,  6,  2, 18, 18, 17,  7, 14,  4, 11, 16,  4, 12,
              7,  1,  5,  2, 12, 12, 17, 16, 18, 13, 19, 14],
            [ 5,  4,  9, 11,  7,  4, 12,  5,  9,  8,  8,  7, 14,  7,  7,  7,  9, 12,
             18, 10, 17, 11,  2, 18,  3,  5, 14,  7, 16, 16]])
    7.204190254211426
    tensor([[[-4.5473, -2.9308, -3.4710,  ..., -5.0862, -4.5390, -3.0019],
             [-3.4926, -3.9439, -2.9775,  ..., -4.8525, -2.0595, -1.9979],
             [-3.6029, -5.2872, -4.5145,  ..., -5.1210, -2.4705, -4.4843],
             ...,
             [-4.1910, -1.5234, -3.5309,  ..., -3.4920, -2.6344, -3.8107],
             [-3.0253, -3.8009, -1.8082,  ..., -1.7154, -4.1993, -3.5755],
             [-4.4555, -4.1369, -2.2524,  ..., -2.2737, -4.8700, -2.7561]],
    
            [[-1.8466, -3.5849, -4.0244,  ..., -3.3694, -2.5299, -4.5665],
             [-3.5848, -4.1891, -1.5201,  ..., -4.0952, -3.1882, -4.2458],
             [-2.8536, -3.9756, -2.9717,  ..., -2.8720, -4.2893, -2.6458],
             ...,
             [-3.7382, -2.9893, -2.4263,  ..., -2.0597, -4.3938, -3.8732],
             [-3.1872, -3.2586, -3.5295,  ..., -3.6112, -3.6354, -3.5260],
             [-3.0909, -3.0465, -4.2621,  ..., -2.8873, -2.5937, -3.0882]],
    
            [[-3.9656, -3.5806, -4.8827,  ..., -3.0376, -2.9565, -1.8247],
             [-3.7559, -6.0353, -3.6398,  ..., -3.6393, -3.2274, -3.0305],
             [-4.1481, -4.2567, -1.4396,  ..., -3.8095, -4.4052, -2.1276],
             ...,
             [-2.3917, -1.7566, -3.0118,  ..., -2.4229, -3.8070, -3.8842],
             [-2.2097, -5.5826, -3.2264,  ..., -3.1023, -6.8980, -3.6250],
             [-4.0733, -3.5903, -3.4987,  ..., -2.7849, -3.4985, -4.4527]],
    
            ...,
    
            [[-3.8715, -4.0438, -2.9394,  ..., -1.7864, -4.6027, -3.2582],
             [-5.5483, -2.4075, -2.7854,  ..., -3.7992, -3.0093, -3.4863],
             [-3.3722, -3.4671, -3.0541,  ..., -2.6499, -3.6659, -2.8567],
             ...,
             [-5.9331, -2.3941, -2.5093,  ..., -2.5179, -3.8158, -3.8728],
             [-5.1388, -4.4442, -4.4178,  ..., -2.3887, -3.7243, -5.1282],
             [-2.1315, -3.0624, -1.2365,  ..., -3.6345, -4.1020, -4.6244]],
    
            [[-4.8256, -3.0160, -3.0610,  ..., -2.0361, -3.4582, -4.0003],
             [-3.3710, -3.8499, -3.7634,  ..., -2.0650, -2.7568, -4.2056],
             [-3.4087, -3.1548, -3.7585,  ..., -4.4898, -2.7430, -3.3884],
             ...,
             [-5.3753, -5.0590, -3.5575,  ..., -3.3909, -4.3682, -3.7099],
             [-1.8904, -2.1434, -4.5993,  ..., -3.1757, -3.6656, -4.4094],
             [-4.1571, -2.8661, -2.2116,  ..., -3.0911, -2.4233, -1.9953]],
    
            [[-2.4579, -3.2395, -2.9720,  ..., -5.6812, -3.5533, -2.4751],
             [-2.1626, -4.2008, -3.7666,  ..., -4.5745, -3.8079, -2.1094],
             [-3.9287, -2.6917, -2.0324,  ..., -3.3660, -3.7597, -4.3927],
             ...,
             [-4.1179, -3.3981, -4.9460,  ..., -3.3150, -3.1188, -1.2154],
             [-3.9446, -4.2823, -3.1389,  ..., -3.6257, -3.6355, -3.4399],
             [-4.6564, -4.4169, -5.0921,  ..., -3.1329, -3.5289, -2.2295]]],
           requires_grad=True)
    tensor([ 7,  1, 16, 13, 19, 11,  6, 15, 11, 16, 14, 19, 19, 11,  3,  6,  9,  5,
            17, 10,  8, 16,  8,  4, 17,  9, 19,  7, 11,  1, 11,  8,  4, 19,  4, 17,
             8, 11,  5, 19, 17, 10,  2, 13, 16,  9,  2,  7,  2,  5, 14, 15,  5,  4,
            12, 13, 16,  5,  8, 10, 15,  1,  4, 17, 12, 15,  8,  6,  3, 13, 19, 10,
            13, 19, 18,  7,  7,  5,  3, 12, 17,  8, 11,  5, 18,  3, 12,  6,  6,  6,
             5, 15,  4,  2,  4,  6, 11, 14,  5,  1,  4, 10,  1,  9,  4, 17, 15, 14,
             5, 13,  2, 10, 18, 16, 12, 11,  4,  6, 18,  5, 16,  7,  9,  3,  2,  5,
             4, 13, 16,  3, 14, 12, 10,  4,  2, 13, 10, 14, 17,  4,  8,  6,  6, 17,
            13, 19,  2, 13,  7, 14, 10, 11,  2, 18,  5,  2,  8, 13,  4, 17,  7,  9,
            12, 10,  8,  6,  9, 14,  9, 15,  9,  2,  7, 16, 13,  3, 19,  1, 19,  2,
            13,  4, 13,  1,  8, 14, 15,  6,  6, 10,  4, 16, 15,  9, 12, 13,  8,  9,
            19, 10, 19,  8, 11,  5,  4,  8, 17,  3, 12, 10,  2, 11, 14, 16,  7,  9,
            11, 19, 14, 18, 15, 18, 13,  2,  7,  1,  2,  5,  3, 10, 11, 12, 11, 17,
             2,  8,  1,  3,  1,  6, 11,  7,  6, 14,  4, 19,  8,  4,  2,  9, 15,  4,
            15, 10,  9,  4,  9, 15, 18,  8,  8,  8,  2, 11, 14,  2,  5, 13, 19,  6,
             3,  4,  5,  2,  2,  5, 19, 14,  4,  6, 11, 18,  3, 15, 17, 15,  5,  2,
             1,  2, 12, 16, 15, 16, 17,  4, 15,  5, 12, 15, 18, 18, 15, 12,  5, 19,
             9,  7,  6, 13,  1, 17,  7, 11,  8, 16, 17,  1, 17, 14,  1,  4,  6,  6,
             6, 15,  3,  5, 11])
    13.858318328857422


## nn.NLLLoss


```python
import torch
import torch.nn as nn

m = nn.LogSoftmax(dim=1)
loss = nn.NLLLoss()
# input is of size N x C = 3 x 5
input = torch.randn(3, 5, requires_grad=True)
# each element in target has to have 0 <= value < C
target = torch.tensor([1, 0, 4])
output = loss(m(input), target)
output.backward()

# 2D loss example (used, for example, with image inputs)
N, C = 5, 4
loss = nn.NLLLoss()
# input is of size N x C x height x width
data = torch.randn(N, 16, 10, 10)
conv = nn.Conv2d(16, C, (3, 3))
m = nn.LogSoftmax(dim=1)
# each element in target has to have 0 <= value < C
target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C)
output = loss(m(conv(data)), target)
output.backward()
print(input)
print(target)
print(output.item())
```

    tensor([[ 0.6712, -2.0666, -0.7198,  0.5157, -0.1520],
            [-0.3969, -0.3136,  0.1934,  0.6004, -1.0659],
            [ 0.1331, -1.0674, -0.2086,  0.3690,  0.8716]], requires_grad=True)
    tensor([[[1, 3, 2, 1, 1, 3, 0, 1],
             [2, 0, 0, 2, 0, 1, 0, 2],
             [0, 1, 0, 0, 1, 0, 2, 1],
             [2, 3, 2, 1, 2, 1, 1, 3],
             [3, 0, 1, 3, 1, 3, 1, 0],
             [0, 0, 3, 0, 2, 2, 3, 3],
             [1, 0, 1, 3, 0, 1, 1, 1],
             [0, 1, 3, 0, 2, 0, 2, 3]],
    
            [[1, 0, 3, 3, 1, 0, 3, 0],
             [1, 2, 0, 3, 0, 2, 2, 2],
             [2, 1, 2, 2, 1, 2, 3, 2],
             [3, 1, 0, 1, 0, 3, 1, 2],
             [1, 0, 2, 3, 2, 2, 2, 0],
             [0, 0, 0, 2, 2, 2, 1, 2],
             [2, 2, 0, 2, 2, 0, 0, 1],
             [2, 0, 1, 0, 1, 1, 2, 0]],
    
            [[1, 0, 2, 1, 2, 2, 2, 0],
             [2, 2, 1, 1, 1, 2, 1, 3],
             [0, 1, 1, 3, 2, 2, 3, 2],
             [1, 0, 2, 3, 0, 3, 0, 3],
             [1, 2, 1, 2, 3, 2, 2, 0],
             [3, 1, 2, 0, 1, 1, 3, 2],
             [3, 2, 3, 3, 2, 3, 1, 2],
             [2, 2, 1, 3, 0, 2, 3, 2]],
    
            [[3, 0, 3, 3, 0, 0, 3, 0],
             [1, 0, 1, 2, 3, 0, 2, 1],
             [0, 0, 1, 1, 1, 3, 2, 3],
             [0, 3, 1, 3, 0, 3, 2, 2],
             [2, 3, 2, 2, 1, 3, 2, 0],
             [0, 0, 3, 2, 1, 1, 1, 0],
             [2, 3, 0, 1, 1, 1, 0, 2],
             [3, 1, 0, 3, 2, 1, 0, 1]],
    
            [[3, 0, 3, 0, 2, 2, 0, 0],
             [2, 3, 2, 3, 2, 3, 0, 3],
             [3, 2, 1, 3, 0, 2, 2, 1],
             [0, 3, 1, 1, 1, 0, 0, 2],
             [1, 3, 2, 1, 1, 0, 2, 1],
             [0, 1, 0, 0, 1, 1, 1, 0],
             [0, 3, 2, 1, 1, 3, 2, 2],
             [0, 2, 2, 1, 0, 3, 2, 2]]])
    1.5315557718276978


## nn.PoissonNLLLoss


```python

import torch
import torch.nn as nn

loss = nn.PoissonNLLLoss()
log_input = torch.randn(5, 2, requires_grad=True)
target = torch.randn(5, 2)
output = loss(log_input, target)
output.backward()
print(input)
print(target)
print(output.item())
```

    tensor([[ 0.6712, -2.0666, -0.7198,  0.5157, -0.1520],
            [-0.3969, -0.3136,  0.1934,  0.6004, -1.0659],
            [ 0.1331, -1.0674, -0.2086,  0.3690,  0.8716]], requires_grad=True)
    tensor([[ 1.5795,  0.3903],
            [-1.7605,  0.5738],
            [-1.2769, -0.0461],
            [ 1.2576,  1.4423],
            [-0.0257,  0.2529]])
    2.2142281532287598


## nn.KLDivLoss
## nn.BCELoss


```python
# 분류가 두가지인 경우 사용

import torch
import torch.nn as nn

m = nn.Sigmoid()
loss = nn.BCELoss()
input = torch.randn(3, requires_grad=True)
target = torch.empty(3).random_(2)
output = loss(m(input), target)
output.backward()
print(input)
print(target)
print(output.item())
```

    tensor([-0.1986, -1.7686,  2.7241], requires_grad=True)
    tensor([0., 0., 1.])
    0.2732710540294647


## nn.BCEWithLogitsLoss


```python
import torch
import torch.nn as nn

loss = nn.BCEWithLogitsLoss()
input = torch.randn(3, requires_grad=True)
target = torch.empty(3).random_(2)
output = loss(input, target)
output.backward()
print(input)
print(target)
print(output.item())
```

    tensor([-0.7563, -0.3336,  2.2182], requires_grad=True)
    tensor([1., 0., 0.])
    1.3342794179916382


## nn.MarginRankingLoss

## nn.MultiLabelMarginLoss


```python
import torch
import torch.nn as nn

loss = nn.MultiLabelMarginLoss()
x = torch.FloatTensor([[0.1, 0.2, 0.4, 0.8]])
# for target y, only consider labels 3 and 0, not after label -1
y = torch.LongTensor([[3, 0, -1, 1]])
output = loss(x, y)
print(x)
print(y)
print(output.item())
```

    tensor([[0.1000, 0.2000, 0.4000, 0.8000]])
    tensor([[ 3,  0, -1,  1]])
    0.8500000238418579


## nn.SmoothL1Loss
## nn.SoftMarginLoss
## nn.MultiLabelSoftMarginLoss
## nn.CosineEmbeddingLoss
## nn.MultiMarginLoss
## nn.TripletMarginLoss


```python
import torch
import torch.nn as nn

triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)
anchor = torch.randn(100, 128, requires_grad=True)
positive = torch.randn(100, 128, requires_grad=True)
negative = torch.randn(100, 128, requires_grad=True)
output = triplet_loss(anchor, positive, negative)
output.backward()
print(input)
print(target)
print(output.item())
```

    tensor([-0.7563, -0.3336,  2.2182], requires_grad=True)
    tensor([1., 0., 0.])
    1.214802861213684

